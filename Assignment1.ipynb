{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK4tXYIZPWgv"
      },
      "source": [
        "\n",
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "* Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5DpJrkwPWgv"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are tasked to address the task of POS tagging.\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/pos_tagging.png\" alt=\"POS tagging\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import zeros\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.vocab import GloVe\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YqCsaSYMRAN1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6UV8pgMPWgw"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
        "\n",
        "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
        "\n",
        "### Example\n",
        "\n",
        "```Pierre\tNNP\t2\n",
        "Vinken\tNNP\t8\n",
        ",\t,\t2\n",
        "61\tCD\t5\n",
        "years\tNNS\t6\n",
        "old\tJJ\t2\n",
        ",\t,\t2\n",
        "will\tMD\t0\n",
        "join\tVB\t8\n",
        "the\tDT\t11\n",
        "board\tNN\t9\n",
        "as\tIN\t9\n",
        "a\tDT\t15\n",
        "nonexecutive\tJJ\t15\n",
        "director\tNN\t12\n",
        "Nov.\tNNP\t9\n",
        "29\tCD\t16\n",
        ".\t.\t8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset download"
      ],
      "metadata": {
        "id": "Evf0B3k4Q20o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
        "!unzip dependency_treebank.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAoEoejnQVc8",
        "outputId": "71bc4f43-7bd7-4a19-9c3e-e9e2727fa088"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  446k  100  446k    0     0  1135k      0 --:--:-- --:--:-- --:--:-- 1136k\n",
            "Archive:  dependency_treebank.zip\n",
            "   creating: dependency_treebank/\n",
            "  inflating: dependency_treebank/wsj_0093.dp  \n",
            "  inflating: dependency_treebank/wsj_0065.dp  \n",
            "  inflating: dependency_treebank/wsj_0039.dp  \n",
            "  inflating: dependency_treebank/wsj_0182.dp  \n",
            "  inflating: dependency_treebank/wsj_0186.dp  \n",
            "  inflating: dependency_treebank/wsj_0041.dp  \n",
            "  inflating: dependency_treebank/wsj_0018.dp  \n",
            "  inflating: dependency_treebank/wsj_0105.dp  \n",
            "  inflating: dependency_treebank/wsj_0149.dp  \n",
            "  inflating: dependency_treebank/wsj_0194.dp  \n",
            "  inflating: dependency_treebank/wsj_0055.dp  \n",
            "  inflating: dependency_treebank/wsj_0187.dp  \n",
            "  inflating: dependency_treebank/wsj_0143.dp  \n",
            "  inflating: dependency_treebank/wsj_0052.dp  \n",
            "  inflating: dependency_treebank/wsj_0064.dp  \n",
            "  inflating: dependency_treebank/wsj_0179.dp  \n",
            "  inflating: dependency_treebank/wsj_0195.dp  \n",
            "  inflating: dependency_treebank/wsj_0051.dp  \n",
            "  inflating: dependency_treebank/wsj_0059.dp  \n",
            "  inflating: dependency_treebank/wsj_0109.dp  \n",
            "  inflating: dependency_treebank/wsj_0074.dp  \n",
            "  inflating: dependency_treebank/wsj_0089.dp  \n",
            "  inflating: dependency_treebank/wsj_0108.dp  \n",
            "  inflating: dependency_treebank/wsj_0104.dp  \n",
            "  inflating: dependency_treebank/wsj_0164.dp  \n",
            "  inflating: dependency_treebank/wsj_0024.dp  \n",
            "  inflating: dependency_treebank/wsj_0008.dp  \n",
            "  inflating: dependency_treebank/wsj_0101.dp  \n",
            "  inflating: dependency_treebank/wsj_0132.dp  \n",
            "  inflating: dependency_treebank/wsj_0028.dp  \n",
            "  inflating: dependency_treebank/wsj_0184.dp  \n",
            "  inflating: dependency_treebank/wsj_0082.dp  \n",
            "  inflating: dependency_treebank/wsj_0114.dp  \n",
            "  inflating: dependency_treebank/wsj_0061.dp  \n",
            "  inflating: dependency_treebank/wsj_0190.dp  \n",
            "  inflating: dependency_treebank/wsj_0034.dp  \n",
            "  inflating: dependency_treebank/wsj_0043.dp  \n",
            "  inflating: dependency_treebank/wsj_0044.dp  \n",
            "  inflating: dependency_treebank/wsj_0021.dp  \n",
            "  inflating: dependency_treebank/wsj_0005.dp  \n",
            "  inflating: dependency_treebank/wsj_0112.dp  \n",
            "  inflating: dependency_treebank/wsj_0167.dp  \n",
            "  inflating: dependency_treebank/wsj_0042.dp  \n",
            "  inflating: dependency_treebank/wsj_0168.dp  \n",
            "  inflating: dependency_treebank/wsj_0185.dp  \n",
            "  inflating: dependency_treebank/wsj_0057.dp  \n",
            "  inflating: dependency_treebank/wsj_0015.dp  \n",
            "  inflating: dependency_treebank/wsj_0116.dp  \n",
            "  inflating: dependency_treebank/wsj_0135.dp  \n",
            "  inflating: dependency_treebank/wsj_0175.dp  \n",
            "  inflating: dependency_treebank/wsj_0171.dp  \n",
            "  inflating: dependency_treebank/wsj_0068.dp  \n",
            "  inflating: dependency_treebank/wsj_0080.dp  \n",
            "  inflating: dependency_treebank/wsj_0035.dp  \n",
            "  inflating: dependency_treebank/wsj_0181.dp  \n",
            "  inflating: dependency_treebank/wsj_0177.dp  \n",
            "  inflating: dependency_treebank/wsj_0102.dp  \n",
            "  inflating: dependency_treebank/wsj_0137.dp  \n",
            "  inflating: dependency_treebank/wsj_0022.dp  \n",
            "  inflating: dependency_treebank/wsj_0176.dp  \n",
            "  inflating: dependency_treebank/wsj_0180.dp  \n",
            "  inflating: dependency_treebank/wsj_0121.dp  \n",
            "  inflating: dependency_treebank/wsj_0128.dp  \n",
            "  inflating: dependency_treebank/wsj_0036.dp  \n",
            "  inflating: dependency_treebank/wsj_0071.dp  \n",
            "  inflating: dependency_treebank/wsj_0091.dp  \n",
            "  inflating: dependency_treebank/wsj_0076.dp  \n",
            "  inflating: dependency_treebank/wsj_0123.dp  \n",
            "  inflating: dependency_treebank/wsj_0075.dp  \n",
            "  inflating: dependency_treebank/wsj_0131.dp  \n",
            "  inflating: dependency_treebank/wsj_0050.dp  \n",
            "  inflating: dependency_treebank/wsj_0136.dp  \n",
            "  inflating: dependency_treebank/wsj_0161.dp  \n",
            "  inflating: dependency_treebank/wsj_0033.dp  \n",
            "  inflating: dependency_treebank/wsj_0188.dp  \n",
            "  inflating: dependency_treebank/wsj_0085.dp  \n",
            "  inflating: dependency_treebank/wsj_0014.dp  \n",
            "  inflating: dependency_treebank/wsj_0073.dp  \n",
            "  inflating: dependency_treebank/wsj_0199.dp  \n",
            "  inflating: dependency_treebank/wsj_0120.dp  \n",
            "  inflating: dependency_treebank/wsj_0178.dp  \n",
            "  inflating: dependency_treebank/wsj_0122.dp  \n",
            "  inflating: dependency_treebank/wsj_0040.dp  \n",
            "  inflating: dependency_treebank/wsj_0020.dp  \n",
            "  inflating: dependency_treebank/wsj_0153.dp  \n",
            "  inflating: dependency_treebank/wsj_0107.dp  \n",
            "  inflating: dependency_treebank/wsj_0017.dp  \n",
            "  inflating: dependency_treebank/wsj_0140.dp  \n",
            "  inflating: dependency_treebank/wsj_0038.dp  \n",
            "  inflating: dependency_treebank/wsj_0031.dp  \n",
            "  inflating: dependency_treebank/wsj_0165.dp  \n",
            "  inflating: dependency_treebank/wsj_0146.dp  \n",
            "  inflating: dependency_treebank/wsj_0090.dp  \n",
            "  inflating: dependency_treebank/wsj_0001.dp  \n",
            "  inflating: dependency_treebank/wsj_0148.dp  \n",
            "  inflating: dependency_treebank/wsj_0097.dp  \n",
            "  inflating: dependency_treebank/wsj_0009.dp  \n",
            "  inflating: dependency_treebank/wsj_0173.dp  \n",
            "  inflating: dependency_treebank/wsj_0111.dp  \n",
            "  inflating: dependency_treebank/wsj_0129.dp  \n",
            "  inflating: dependency_treebank/wsj_0130.dp  \n",
            "  inflating: dependency_treebank/wsj_0047.dp  \n",
            "  inflating: dependency_treebank/wsj_0110.dp  \n",
            "  inflating: dependency_treebank/wsj_0113.dp  \n",
            "  inflating: dependency_treebank/wsj_0147.dp  \n",
            "  inflating: dependency_treebank/wsj_0160.dp  \n",
            "  inflating: dependency_treebank/wsj_0099.dp  \n",
            "  inflating: dependency_treebank/wsj_0003.dp  \n",
            "  inflating: dependency_treebank/wsj_0011.dp  \n",
            "  inflating: dependency_treebank/wsj_0056.dp  \n",
            "  inflating: dependency_treebank/wsj_0069.dp  \n",
            "  inflating: dependency_treebank/wsj_0026.dp  \n",
            "  inflating: dependency_treebank/wsj_0138.dp  \n",
            "  inflating: dependency_treebank/wsj_0029.dp  \n",
            "  inflating: dependency_treebank/wsj_0115.dp  \n",
            "  inflating: dependency_treebank/wsj_0037.dp  \n",
            "  inflating: dependency_treebank/wsj_0019.dp  \n",
            "  inflating: dependency_treebank/wsj_0002.dp  \n",
            "  inflating: dependency_treebank/wsj_0007.dp  \n",
            "  inflating: dependency_treebank/wsj_0158.dp  \n",
            "  inflating: dependency_treebank/wsj_0087.dp  \n",
            "  inflating: dependency_treebank/wsj_0157.dp  \n",
            "  inflating: dependency_treebank/wsj_0083.dp  \n",
            "  inflating: dependency_treebank/wsj_0103.dp  \n",
            "  inflating: dependency_treebank/wsj_0058.dp  \n",
            "  inflating: dependency_treebank/wsj_0054.dp  \n",
            "  inflating: dependency_treebank/wsj_0016.dp  \n",
            "  inflating: dependency_treebank/wsj_0126.dp  \n",
            "  inflating: dependency_treebank/wsj_0198.dp  \n",
            "  inflating: dependency_treebank/wsj_0144.dp  \n",
            "  inflating: dependency_treebank/wsj_0096.dp  \n",
            "  inflating: dependency_treebank/wsj_0086.dp  \n",
            "  inflating: dependency_treebank/wsj_0197.dp  \n",
            "  inflating: dependency_treebank/wsj_0025.dp  \n",
            "  inflating: dependency_treebank/wsj_0100.dp  \n",
            "  inflating: dependency_treebank/wsj_0084.dp  \n",
            "  inflating: dependency_treebank/wsj_0098.dp  \n",
            "  inflating: dependency_treebank/wsj_0106.dp  \n",
            "  inflating: dependency_treebank/wsj_0119.dp  \n",
            "  inflating: dependency_treebank/wsj_0092.dp  \n",
            "  inflating: dependency_treebank/wsj_0134.dp  \n",
            "  inflating: dependency_treebank/wsj_0077.dp  \n",
            "  inflating: dependency_treebank/wsj_0060.dp  \n",
            "  inflating: dependency_treebank/wsj_0172.dp  \n",
            "  inflating: dependency_treebank/wsj_0048.dp  \n",
            "  inflating: dependency_treebank/wsj_0030.dp  \n",
            "  inflating: dependency_treebank/wsj_0192.dp  \n",
            "  inflating: dependency_treebank/wsj_0066.dp  \n",
            "  inflating: dependency_treebank/wsj_0045.dp  \n",
            "  inflating: dependency_treebank/wsj_0155.dp  \n",
            "  inflating: dependency_treebank/wsj_0118.dp  \n",
            "  inflating: dependency_treebank/wsj_0152.dp  \n",
            "  inflating: dependency_treebank/wsj_0012.dp  \n",
            "  inflating: dependency_treebank/wsj_0006.dp  \n",
            "  inflating: dependency_treebank/wsj_0159.dp  \n",
            "  inflating: dependency_treebank/wsj_0163.dp  \n",
            "  inflating: dependency_treebank/wsj_0170.dp  \n",
            "  inflating: dependency_treebank/wsj_0141.dp  \n",
            "  inflating: dependency_treebank/wsj_0117.dp  \n",
            "  inflating: dependency_treebank/wsj_0125.dp  \n",
            "  inflating: dependency_treebank/wsj_0094.dp  \n",
            "  inflating: dependency_treebank/wsj_0169.dp  \n",
            "  inflating: dependency_treebank/wsj_0027.dp  \n",
            "  inflating: dependency_treebank/wsj_0010.dp  \n",
            "  inflating: dependency_treebank/wsj_0162.dp  \n",
            "  inflating: dependency_treebank/wsj_0127.dp  \n",
            "  inflating: dependency_treebank/wsj_0142.dp  \n",
            "  inflating: dependency_treebank/wsj_0046.dp  \n",
            "  inflating: dependency_treebank/wsj_0088.dp  \n",
            "  inflating: dependency_treebank/wsj_0079.dp  \n",
            "  inflating: dependency_treebank/wsj_0174.dp  \n",
            "  inflating: dependency_treebank/wsj_0063.dp  \n",
            "  inflating: dependency_treebank/wsj_0023.dp  \n",
            "  inflating: dependency_treebank/wsj_0004.dp  \n",
            "  inflating: dependency_treebank/wsj_0156.dp  \n",
            "  inflating: dependency_treebank/wsj_0133.dp  \n",
            "  inflating: dependency_treebank/wsj_0032.dp  \n",
            "  inflating: dependency_treebank/wsj_0070.dp  \n",
            "  inflating: dependency_treebank/wsj_0154.dp  \n",
            "  inflating: dependency_treebank/wsj_0095.dp  \n",
            "  inflating: dependency_treebank/wsj_0072.dp  \n",
            "  inflating: dependency_treebank/wsj_0183.dp  \n",
            "  inflating: dependency_treebank/wsj_0081.dp  \n",
            "  inflating: dependency_treebank/wsj_0196.dp  \n",
            "  inflating: dependency_treebank/wsj_0062.dp  \n",
            "  inflating: dependency_treebank/wsj_0124.dp  \n",
            "  inflating: dependency_treebank/wsj_0191.dp  \n",
            "  inflating: dependency_treebank/wsj_0013.dp  \n",
            "  inflating: dependency_treebank/wsj_0078.dp  \n",
            "  inflating: dependency_treebank/wsj_0150.dp  \n",
            "  inflating: dependency_treebank/wsj_0049.dp  \n",
            "  inflating: dependency_treebank/wsj_0189.dp  \n",
            "  inflating: dependency_treebank/wsj_0151.dp  \n",
            "  inflating: dependency_treebank/wsj_0193.dp  \n",
            "  inflating: dependency_treebank/wsj_0067.dp  \n",
            "  inflating: dependency_treebank/wsj_0145.dp  \n",
            "  inflating: dependency_treebank/wsj_0139.dp  \n",
            "  inflating: dependency_treebank/wsj_0166.dp  \n",
            "  inflating: dependency_treebank/wsj_0053.dp  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkhLvBtRPWgw"
      },
      "source": [
        "### Splits\n",
        "\n",
        "The corpus contains 200 documents.\n",
        "\n",
        "   * **Train**: Documents 1-100\n",
        "   * **Validation**: Documents 101-150\n",
        "   * **Test**: Documents 151-199"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset import"
      ],
      "metadata": {
        "id": "MtoJ6bs_RBnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_pad(x, tot_len):\n",
        "  l = len(x)\n",
        "  return ''.join(['0' for _ in range(4 - l)]) + x"
      ],
      "metadata": {
        "id": "etSG9VDOTq7G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_corpus(folder:'str', file_base:'str', corpus_range:'range', separator:'str', data:'object'):\n",
        "  keys = list(data.keys())\n",
        "  data_len = len(keys)\n",
        "  for i in range(1, 101):\n",
        "    f = open(f'{folder}/{file_base}{zero_pad(str(i), 4)}.dp')\n",
        "    for line in f.readlines():\n",
        "      entry = line.replace('\\n','').split(separator)\n",
        "      if len(entry) >= data_len:\n",
        "        for i in range(data_len):\n",
        "            data[keys[i]].append(entry[i])\n",
        "        data['source file'] = f'{file_base}{zero_pad(str(i), 4)}'\n",
        "    f.close()\n",
        "  return data"
      ],
      "metadata": {
        "id": "LCRhF-RDVrOw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEPARATOR = '\\t'\n",
        "folder = 'dependency_treebank'\n",
        "file_base = 'wsj_'\n",
        "\n",
        "train_data = pd.DataFrame(import_corpus(folder, file_base, range(1,101), SEPARATOR, {'word/symbol':[], 'pos label':[]}))\n",
        "validation_data = pd.DataFrame(import_corpus(folder, file_base, range(101,151), SEPARATOR, {'word/symbol':[], 'pos label':[]}))\n",
        "test_data = pd.DataFrame(import_corpus(folder, file_base, range(151,200), SEPARATOR, {'word/symbol':[], 'pos label':[]}))\n",
        "train_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "8nnJIIQITbFq",
        "outputId": "ac8ad335-51f3-4639-dd44-611b1b7aeb89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  word/symbol pos label source file\n",
              "0      Pierre       NNP    wsj_0001\n",
              "1      Vinken       NNP    wsj_0001\n",
              "2           ,         ,    wsj_0001\n",
              "3          61        CD    wsj_0001\n",
              "4       years       NNS    wsj_0001\n",
              "5         old        JJ    wsj_0001\n",
              "6           ,         ,    wsj_0001\n",
              "7        will        MD    wsj_0001\n",
              "8        join        VB    wsj_0001\n",
              "9         the        DT    wsj_0001"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c9acc01-d6ac-4bb1-afd1-98d33e3249c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word/symbol</th>\n",
              "      <th>pos label</th>\n",
              "      <th>source file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pierre</td>\n",
              "      <td>NNP</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vinken</td>\n",
              "      <td>NNP</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>CD</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>years</td>\n",
              "      <td>NNS</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>old</td>\n",
              "      <td>JJ</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>will</td>\n",
              "      <td>MD</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>join</td>\n",
              "      <td>VB</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>wsj_0001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c9acc01-d6ac-4bb1-afd1-98d33e3249c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c9acc01-d6ac-4bb1-afd1-98d33e3249c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c9acc01-d6ac-4bb1-afd1-98d33e3249c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d549ac68-049e-40c9-9ef7-15e4eb701d57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d549ac68-049e-40c9-9ef7-15e4eb701d57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d549ac68-049e-40c9-9ef7-15e4eb701d57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WveiIg-UPWgx"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Download** the corpus.\n",
        "* **Encode** the corpus into a pandas.DataFrame object.\n",
        "* **Split** it in training, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhiw3MBkPWgx"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuqriwPkPWgx"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = GloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "id": "Zv4zgrWuTvUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ad9af7-01c2-44db-941c-0dd4502a0a3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:23<00:00, 16772.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 50\n",
        "word = train_data.iloc[i][\"word/symbol\"]\n",
        "print(f\"word at position {i}: {word}\")\n",
        "print(f'embedding: \\n {glove[word]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFWwF1YUKkG",
        "outputId": "b65c55e1-4ce4-43e4-b1a5-a4160e2f002b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word at position 50: director\n",
            "embedding: \n",
            " tensor([ 2.6554e-01, -7.8286e-01, -8.8447e-02, -1.0131e+00,  9.9533e-01,\n",
            "        -9.4081e-01, -3.6870e-01,  3.3595e-01, -6.6131e-01,  1.8660e-02,\n",
            "        -1.0583e-01, -5.0757e-01,  4.3957e-01,  1.1668e-01,  6.8358e-03,\n",
            "        -1.6246e-01,  8.3221e-01, -2.9842e-02, -5.8107e-01,  5.9797e-01,\n",
            "        -3.4653e-01,  3.3801e-01,  8.3349e-02, -3.3689e-01, -1.5555e-01,\n",
            "         3.0370e-01,  3.6218e-01, -4.9779e-01, -1.0420e-01,  2.3055e-01,\n",
            "        -9.2252e-01,  6.0625e-01, -3.4707e-01,  3.9155e-01, -1.1208e+00,\n",
            "        -5.4766e-02,  9.1888e-02,  1.3057e+00,  1.7112e-01, -4.7524e-01,\n",
            "        -3.8920e-01, -6.1009e-02, -6.0362e-01,  4.8490e-01,  8.2905e-01,\n",
            "         1.9803e-01, -7.3324e-01, -5.5246e-01, -4.6930e-01, -1.7326e-01,\n",
            "         2.5662e-01, -1.0521e+00, -3.2560e-01,  1.3647e-01,  1.2832e-01,\n",
            "        -2.4086e+00, -2.8245e-01,  7.1802e-01,  8.7841e-01,  7.1353e-02,\n",
            "         5.3584e-01,  5.7417e-01,  5.6343e-01, -1.2018e-01,  5.0456e-01,\n",
            "        -6.1081e-01,  4.9771e-01,  1.2290e+00,  7.7136e-01,  1.2948e+00,\n",
            "         7.4913e-01,  1.6564e-01, -2.8906e-01, -5.0207e-01,  3.1034e-01,\n",
            "        -8.0094e-01, -7.7947e-01,  2.1794e-01, -1.0672e+00, -2.2227e-01,\n",
            "         3.4507e-01, -1.3336e-01, -5.8961e-02,  2.1234e-01, -1.4277e+00,\n",
            "         7.4573e-02, -3.1233e-01, -5.3944e-04,  1.5698e-01, -1.0382e+00,\n",
            "         9.8328e-01, -5.9559e-01,  4.3997e-01,  5.5026e-01,  3.6462e-01,\n",
            "         8.4136e-01, -1.4328e-03, -2.4872e-01, -1.0055e-01,  9.5509e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful classes"
      ],
      "metadata": {
        "id": "fF6zaZQl2aDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "it is a usefull class that helps creating a dataloader which is very usefull for training a network since it automatically manages batches"
      ],
      "metadata": {
        "id": "Cpf8ylTl2eMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "SDdt_6ytPtLc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary\n",
        "It is a class that really helps with managing the words in our dataset. it creates 3 structures:\n",
        "  - `word2idx` which is a dictionary that maps every word to the corresponding token.\n",
        "  - `idx2word` which is a list that works as the inverse function to `word2idx` mapping back every token to the corresponding word.\n",
        "  - `vectors` which is a list that maps every token to the corresponding embedding vector. If no embedding vector has been given for the corresponding word, the vectors list will return a 0 tensor.\n",
        "\n",
        "In addition, the `length` variable will contains the length of the embedding vectors and `dim` will contains the size of the vocabulary."
      ],
      "metadata": {
        "id": "MsNOjTC02-qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "  \"\"\"\n",
        "  A class containing all the words used in the training.\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  word2idx : Dict\n",
        "    Maps every word to the corresponding token.\n",
        "  idx2word : List[str]\n",
        "    Works as the inverse function to `word2idx` mapping back every token to the corresponding word.\n",
        "  vectors : list[torch.Tensor]\n",
        "    maps every token to the corresponding embedding vector. If no embedding vector has been given for the corresponding word, the vectors list will return a 0 tensor.\n",
        "  length : int\n",
        "    contains the length of the embedding vectors.\n",
        "  dim : int\n",
        "    contains the size of the vocabulary.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               words:'list[str]',\n",
        "               pretrained_vectors: 'torchtext.vocab.Vectors' = None,\n",
        "               specials:'list[str]' = ['<unk>', '<pad>'],\n",
        "               vectors_length:'int' = -1) -> None:\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    words: list[str]\n",
        "      The unique words contained in the vocabulary\n",
        "    pretrained_vectors: torchtext.vocab.Vectors\n",
        "      the pretrained embedding containing the Tensors that will be used for the embedding. If there are words included in this class not included in the `words` list they will be added to the vocabulary too.\n",
        "      It can be None but, in this case, a 0 Tensor will be created for the embedding. In the case this value is None, the `vectors_length` is mandatory.\n",
        "    specials: list[str]\n",
        "      A list that contains the special tokens that will be added to the vocabulary. This token will be the first tokens in the resulting list.\n",
        "    vectors_length: int\n",
        "      This parameter is mandatory only if the `pretrained_vectors` parameter is None. It represent the length of each Tensor used in the embedding.\n",
        "    \"\"\"\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = []\n",
        "    self.vectors = []\n",
        "\n",
        "    self.pre_trained = pretrained_vectors != None\n",
        "\n",
        "    pre_keys = []\n",
        "    pre_vectors = {}\n",
        "\n",
        "    if self.pre_trained:\n",
        "      pre_keys = pretrained_vectors.stoi.keys()\n",
        "      pre_vectors = pretrained_vectors\n",
        "\n",
        "    self.length = vectors_length\n",
        "    if self.pre_trained:\n",
        "      self.length = len(pretrained_vectors.vectors[0])\n",
        "      if vectors_length != -1 and self.length != vectors_length:\n",
        "        raise Exception(f\"vectors_length {vectors_length} incompatible with length of pretrained_vectors {self.length}. Consider removing the vector length property\")\n",
        "    if self.length == -1:\n",
        "      raise Exception(\"either a the pretrained_vectors or the vectors_length properties should be provided\")\n",
        "\n",
        "    idx = 0\n",
        "\n",
        "    for word in specials:\n",
        "      self.__add_word(word, idx, pre_keys, pre_vectors)\n",
        "      idx += 1\n",
        "\n",
        "    for word in pre_keys:\n",
        "      self.__add_word(word, idx, pre_keys, pre_vectors)\n",
        "      idx += 1\n",
        "\n",
        "    for word in words:\n",
        "      if not word in self.word2idx:\n",
        "        self.__add_word(word, idx, pre_keys, pre_vectors)\n",
        "        idx += 1\n",
        "\n",
        "    self.dim = idx\n",
        "    self.vectors = torch.stack(self.vectors)\n",
        "\n",
        "  def __add_word(self, word:'str', idx:'int', pre_keys:'list', pre_vectors: 'dict') -> None:\n",
        "      self.word2idx[word] = idx\n",
        "      self.idx2word.append(word)\n",
        "      self.vectors.append(pre_vectors[word] if word in pre_keys else zeros(self.length))"
      ],
      "metadata": {
        "id": "5ovAQ8a33uFU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = Vocabulary(np.unique(train_data['word/symbol']), glove)"
      ],
      "metadata": {
        "id": "ujVbEWbDVTk_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary.word2idx['hello'])\n",
        "print(vocabulary.idx2word[13077])\n",
        "print(vocabulary.vectors[13077])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeOkToIgXNdA",
        "outputId": "e9a2b22b-9ad1-4e3f-d865-d4713ace43cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13077\n",
            "hello\n",
            "tensor([ 0.2669,  0.3963,  0.6169, -0.7745, -0.1039,  0.2670,  0.2788,  0.3099,\n",
            "         0.0055, -0.0853,  0.7360, -0.0984,  0.5479, -0.0303,  0.3348,  0.1409,\n",
            "        -0.0070,  0.3257,  0.2290,  0.4656, -0.1953,  0.3749, -0.7139, -0.5178,\n",
            "         0.7704,  1.0881, -0.6601, -0.1623,  0.9119,  0.2105,  0.0475,  1.0019,\n",
            "         1.1133,  0.7009, -0.0870,  0.4757,  0.1636, -0.4447,  0.4469, -0.9382,\n",
            "         0.0131,  0.0860, -0.6746,  0.4966, -0.0378, -0.1104, -0.2861,  0.0746,\n",
            "        -0.3153, -0.0938, -0.5707,  0.6686,  0.4531, -0.3415, -0.7166, -0.7527,\n",
            "         0.0752,  0.5790, -0.1191, -0.1138, -0.1003,  0.7134, -1.1574, -0.7403,\n",
            "         0.4045,  0.1802,  0.2145,  0.3764,  0.1124, -0.5364, -0.0251,  0.3189,\n",
            "        -0.2501, -0.6328, -0.0118,  1.3770,  0.8601,  0.2048, -0.3681, -0.6887,\n",
            "         0.5351, -0.4656,  0.2739,  0.4118, -0.8540, -0.0463,  0.1130, -0.2733,\n",
            "         0.1564, -0.2033,  0.5359,  0.5978,  0.6047,  0.1373,  0.4223, -0.6128,\n",
            "        -0.3849,  0.3584, -0.4846,  0.3073])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing and preparation\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i_CHOUNA8oMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PosEncoding\n",
        "It is a similar class to Vocabulary but for the position. It works basically the same but with the one-hot-encoding instead of the embedding."
      ],
      "metadata": {
        "id": "J9_H2yulB7Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PosEncoding:\n",
        "  \"\"\"\n",
        "  A class containing all the pos values used in the training.\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  pos2idx : Dict\n",
        "    Maps every pos to the corresponding token.\n",
        "  idx2pos : List[str]\n",
        "    Works as the inverse function to `pos2idx` mapping back every token to the corresponding pos.\n",
        "  encoding : list[torch.Tensor]\n",
        "    maps every pos to the corresponding one-hot-encoded vector.\n",
        "  dim : int\n",
        "    contains the size of the vocabulary.\n",
        "  \"\"\"\n",
        "  def __init__(self, pos_labels: 'list[str]', specials:'list[str]' = ['<pad>']) -> None:\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    pos_labels: list[str]\n",
        "      The unique words contained in the vocabulary\n",
        "    specials: list[str]\n",
        "      A list that contains the special pos that will be added to the vocabulary.\n",
        "    \"\"\"\n",
        "    self.pos2idx = {}\n",
        "    self.idx2pos = []\n",
        "    self.encoding = []\n",
        "    starting_tensor = zeros(len(pos_labels) + len(specials))\n",
        "    idx = 0\n",
        "\n",
        "    for pos in specials:\n",
        "      self.__add_pos(pos, idx, starting_tensor)\n",
        "      idx += 1\n",
        "\n",
        "    for pos in pos_labels:\n",
        "      self.__add_pos(pos, idx, starting_tensor)\n",
        "      idx += 1\n",
        "\n",
        "\n",
        "  def __add_pos(self, pos:'str', idx:'int', starting_tensor:'torch.Tensor'):\n",
        "    self.pos2idx[pos] = idx\n",
        "    self.idx2pos.append(pos)\n",
        "    self.encoding.append(starting_tensor.detach().clone())\n",
        "    self.encoding[idx][idx] = 1\n"
      ],
      "metadata": {
        "id": "AXhmgSD19yGf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y encoding"
      ],
      "metadata": {
        "id": "j4KVceH88sfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_labels = np.unique(train_data['pos label'])\n",
        "number_of_pos_labels = len(pos_labels)\n",
        "print(f'there are {number_of_pos_labels} unique pos label values: ' + \"\\n -\" + \"\\n- \".join(pos_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGudSj4L8yS5",
        "outputId": "0f8df95e-06af-4aec-baab-8441fa90c7ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 45 unique pos label values: \n",
            " -#\n",
            "- $\n",
            "- ''\n",
            "- ,\n",
            "- -LRB-\n",
            "- -RRB-\n",
            "- .\n",
            "- :\n",
            "- CC\n",
            "- CD\n",
            "- DT\n",
            "- EX\n",
            "- FW\n",
            "- IN\n",
            "- JJ\n",
            "- JJR\n",
            "- JJS\n",
            "- LS\n",
            "- MD\n",
            "- NN\n",
            "- NNP\n",
            "- NNPS\n",
            "- NNS\n",
            "- PDT\n",
            "- POS\n",
            "- PRP\n",
            "- PRP$\n",
            "- RB\n",
            "- RBR\n",
            "- RBS\n",
            "- RP\n",
            "- SYM\n",
            "- TO\n",
            "- UH\n",
            "- VB\n",
            "- VBD\n",
            "- VBG\n",
            "- VBN\n",
            "- VBP\n",
            "- VBZ\n",
            "- WDT\n",
            "- WP\n",
            "- WP$\n",
            "- WRB\n",
            "- ``\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_encoding = PosEncoding(pos_labels)"
      ],
      "metadata": {
        "id": "8eRA4uJaCLyC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_encoding.pos2idx['NNP'])\n",
        "print(pos_encoding.idx2pos[21])\n",
        "print(pos_encoding.encoding[21])\n",
        "print(pos_encoding.encoding[21][21])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu9QGLrlCiYt",
        "outputId": "55bc9f41-b050-45d4-c9bb-8cc7d38e630f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "NNP\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data['word/symbol'].apply(lambda x: vocabulary.word2idx[x]).values\n",
        "y_train = [pos_encoding.encoding[pos_encoding.pos2idx[x]] for x in train_data['pos label']]\n",
        "\n",
        "x_validation = validation_data['word/symbol'].apply(lambda x: vocabulary.word2idx[x]).values\n",
        "y_validation = [pos_encoding.encoding[pos_encoding.pos2idx[x]] for x in validation_data['pos label']]"
      ],
      "metadata": {
        "id": "06j2xmDpQU3n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bJHoUF-PWgx"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bPdqU-PWg0"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device: %s' % device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6gHqF1O9xYd",
        "outputId": "ffbeb9f1-a644-4feb-d7d6-c0a0e6fc4fb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Layer\n",
        "\n",
        "A very simple layer. It creates a LSTM that can be used with the `NeuralNetwork` class."
      ],
      "metadata": {
        "id": "DyZr-MXqE2pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMLayer(nn.Module):\n",
        "  \"\"\"\n",
        "  A very simple layer. It creates a LSTM that can be used with the `NeuralNetwork` class.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_size:'int', hidden_size:'int', bidirectional:'bool') -> None:\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_size: int\n",
        "      The size of the input to the LSTM layer.\n",
        "    hidden_size: int\n",
        "      The number of LSTM layers.\n",
        "    bidirectional: bool\n",
        "      If the LSTM layer are birectional or not.\n",
        "    \"\"\"\n",
        "    super(LSTMLayer, self).__init__()\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, _ = self.lstm(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "XmlrTkavE68H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embed Layer\n",
        "\n",
        "This layer handles the embedding of the tokens. It contains two embedding layers: the first assumes that there are pretrained vectors to use \\(vector given as arguments to the `__init__` function\\), the second one covers the values that are not present in the pretrained vector. The second embedding layer will be initialized with random values.\n",
        "\n",
        "The first embedding layer can be frozen in order to avoid training it."
      ],
      "metadata": {
        "id": "wmEFLqd3FITE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How the Embedding layer works ![img](https://drive.google.com/uc?export=view&id=1RvlluFhPp9d4uVFWuI7mHUnCRa1acP1m)"
      ],
      "metadata": {
        "id": "WKNXUbVdGwjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbedLayer_replace(nn.Module):\n",
        "  def __init__(self, vocabulary, embedding_dim):\n",
        "        super(EmbedLayer_replace, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocabulary.vectors)\n",
        "        self.oov_embedding = nn.Embedding(vocabulary.dim, embedding_dim)\n",
        "        nn.init.uniform_(self.oov_embedding.weight, -1.0, 1.0)\n",
        "\n",
        "  def freeze(self, freeze:'bool'):\n",
        "    self.embedding.freeze = freeze\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    oov_mask = x >= len(self.embedding.weight)\n",
        "\n",
        "    # Use OOV embeddings for OOV words\n",
        "    oov_indices = oov_mask.nonzero()\n",
        "    oov_indices = oov_indices[:, 0]\n",
        "    oov_embeds = self.oov_embedding(x[oov_indices])\n",
        "    embedded[oov_indices] = oov_embeds\n",
        "    return embedded\n"
      ],
      "metadata": {
        "id": "2_2LSqC0GENZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This second version of the embedding works a bit differently: It sums the two embedding values instead of replacing the oov words only. The second random embedding should \\(hopefully\\) work as \"fine-tuning\" layer for training words and be the only embedding for non-pretrained words. We should try and see which version works the best  "
      ],
      "metadata": {
        "id": "duNiM5h_gXoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbedLayer_sum(nn.Module):\n",
        "  def __init__(self, vocabulary, embedding_dim):\n",
        "        super(EmbedLayer_sum, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocabulary.vectors)\n",
        "        self.oov_embedding = nn.Embedding(vocabulary.dim, embedding_dim)\n",
        "        nn.init.uniform_(self.oov_embedding.weight, -1.0, 1.0)\n",
        "\n",
        "  def freeze(self, freeze:'bool'):\n",
        "    self.embedding.freeze = freeze\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    pre_trained_embedded = self.embedding(x)\n",
        "\n",
        "    oov_embeds = self.oov_embedding(x)\n",
        "    return pre_trained_embedded + oov_embeds"
      ],
      "metadata": {
        "id": "1fs__rBUgBAR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NeuralNetwork\n",
        "This class is a really simple class that helps with crating a neural network. The constructor needs the optimizer and the loss that are gonna be useful for for training and the device on which the network will be trained. Each parameter can be updated in a second moment.\n",
        "### Methods\n",
        " - The add method can be used to add layers to the nn.\n",
        " - The compile method can be used to actually create the nn \\(the order of the layers will be the same as the order they have been passed to the add method\\)\n",
        " - The train method can be used to train the nn"
      ],
      "metadata": {
        "id": "CApiISQ1D18z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, optimizer = torch.optim.Adam, loss = nn.CrossEntropyLoss(), device:'str' = 'cpu'):\n",
        "      self.layers = []\n",
        "      self.net = None\n",
        "      self.optimizer = optimizer\n",
        "      self.loss = loss\n",
        "      self.device = device\n",
        "\n",
        "  def add(self, *layer:'nn.Module'):\n",
        "    self.layers += layer\n",
        "\n",
        "  def compile(self):\n",
        "    self.net = nn.Sequential(*self.layers)\n",
        "    self.net = self.net.to(self.device)\n",
        "    return self\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "     return f\"{self.net}\"\n",
        "\n",
        "  def __calculate_accuracy(self, best_guesses, targets):\n",
        "    num_correct = torch.eq(targets, best_guesses).sum().item()\n",
        "    total_guesses = len(targets)\n",
        "    correct_percentage = num_correct/total_guesses\n",
        "    return correct_percentage\n",
        "\n",
        "  def __validate(self, val_loader):\n",
        "    val_losses = []\n",
        "    val_accuracy = []\n",
        "    net = self.net\n",
        "    # set net to evaluating (testing)\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(val_loader):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # net forward\n",
        "            outputs = net(inputs) # this gets the prediction from the network\n",
        "\n",
        "            # calculate loss\n",
        "            loss = self.loss(outputs, labels)\n",
        "            val_losses.append(loss) # append current average training loss to a buffer variable, for plotting learning curve\n",
        "\n",
        "            # calculate validation accuracy\n",
        "            predicted_classes = torch.max(outputs, 1)[1] # get class from network's prediction\n",
        "            val_accuracy.append(self.__calculate_accuracy(predicted_classes.cpu(), labels.cpu()))\n",
        "\n",
        "    average_val_loss = sum(val_losses)/(batch_idx+1)\n",
        "    average_val_accuracy = sum(val_accuracy)/len(val_loader)\n",
        "    return average_val_accuracy, average_val_loss\n",
        "\n",
        "  def train(self, x_train, y_train, x_validation, y_validation, learning_rate = .1, epochs= 10, batch_size = 50, shuffle = False):\n",
        "    net = self.net\n",
        "    optimizer = self.optimizer(net.parameters(), learning_rate)\n",
        "\n",
        "    train_dataset = Dataset(x_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    validation_dataset = Dataset(x_validation, y_validation)\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Create lists to store training and validation history\n",
        "    train_loss_history = []\n",
        "    train_accuracy_history = []\n",
        "    val_loss_history = []\n",
        "    val_accuracy_history = []\n",
        "\n",
        "    start_ts = time.time()\n",
        "\n",
        "    total_batch = int(len(train_loader.dataset) / train_loader.batch_size)\n",
        "\n",
        "    # ----------------- TRAINING  -------------------- #\n",
        "    # loop for every epoch (training + evaluation)\n",
        "    for epoch in range(epochs):\n",
        "        net.train() # set model to training\n",
        "        # loop for every batch of images in the dataset\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
        "            # Compute prediction (forward input in the model)\n",
        "            outputs = net(inputs)\n",
        "            outputs = outputs.reshape(labels.shape)\n",
        "            # Compute prediction error with the loss function\n",
        "            loss = self.loss(outputs, labels)\n",
        "            # gradients to zero for every batch of data\n",
        "            loss.backward()\n",
        "            # Backpropagation\n",
        "            optimizer.step()\n",
        "            # Optimizer step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #compute training loss\n",
        "            predicted_classes = torch.max(outputs, 1)[1]\n",
        "            normal_labels = torch.max(labels, 1)[1]\n",
        "            accuracy = self.__calculate_accuracy(predicted_classes.cpu(), normal_labels.cpu())\n",
        "            # calculate training accuracy\n",
        "            print(f\"batch {batch_idx + 1}/{total_batch} ----- loss: {loss.cpu()} ----- accuracy: {accuracy} \")\n",
        "\n",
        "        # ----------------- VALIDATION  ----------------- #\n",
        "        val_accuracy, val_loss = self.__validate(val_loader, accuracy_score)\n",
        "        val_accuracy_history.append(val_accuracy)\n",
        "        val_loss_history.append(val_loss)\n",
        "        train_accuracy, train_loss = self.__validate(train_loader, accuracy_score)\n",
        "        train_accuracy_history.append(train_accuracy)\n",
        "        train_loss_history.append(train_loss)\n",
        "        # print training/validation Accuracy and Loss\n",
        "        print(\"======================================================================================================================================\")\n",
        "        print(f\"EPOCH {epoch + 1} training loss: {train_loss_history[-1]} - validation loss: {val_loss_history[-1]}\")\n",
        "        print(f\"EPOCH {epoch + 1} training accuracy: {train_accuracy_history[-1]} - validation accuracy: {val_accuracy_history[-1]}\")\n",
        "        print(\"======================================================================================================================================\")\n",
        "\n",
        "    return train_loss_history, train_accuracy_history, val_loss_history, val_accuracy_history"
      ],
      "metadata": {
        "id": "0gRFP9OJ6mWn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_layer = EmbedLayer_replace(vocabulary, 100)\n",
        "embed_layer.freeze(True)\n",
        "baseline = NeuralNetwork()\n",
        "baseline.add(embed_layer,\n",
        "          LSTMLayer(100, 1000, True),\n",
        "          nn.Linear(1000 * 2, len(y_train[0])))\n",
        "print(baseline.compile())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxduiNiFD14l",
        "outputId": "5d2f0e66-f9af-4b80-f58b-921e2d5a778e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): EmbedLayer_replace(\n",
            "    (embedding): Embedding(402348, 100)\n",
            "    (oov_embedding): Embedding(402348, 100)\n",
            "  )\n",
            "  (1): LSTMLayer(\n",
            "    (lstm): LSTM(100, 1000, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (2): Linear(in_features=2000, out_features=46, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_layer = EmbedLayer_replace(vocabulary, 100)\n",
        "embed_layer.freeze(True)\n",
        "Model1 = NeuralNetwork()\n",
        "Model1.add(embed_layer,\n",
        "          LSTMLayer(100, 1000, True),\n",
        "          LSTMLayer(1000 * 2, 1000, True),\n",
        "          nn.Linear(1000 * 2, len(y_train[0])))\n",
        "print(Model1.compile())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uUh_OdCLmmI",
        "outputId": "683ba428-40c4-4760-febb-8232746cf65e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): EmbedLayer_replace(\n",
            "    (embedding): Embedding(402348, 100)\n",
            "    (oov_embedding): Embedding(402348, 100)\n",
            "  )\n",
            "  (1): LSTMLayer(\n",
            "    (lstm): LSTM(100, 1000, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (2): LSTMLayer(\n",
            "    (lstm): LSTM(2000, 1000, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (3): Linear(in_features=2000, out_features=46, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_layer = EmbedLayer_replace(vocabulary, 100)\n",
        "embed_layer.freeze(True)\n",
        "model2 = NeuralNetwork()\n",
        "model2.add(embed_layer,\n",
        "          LSTMLayer(100, 1000, True),\n",
        "          nn.Linear(1000 * 2, 1000),\n",
        "          nn.Linear(1000, len(y_train[0])))\n",
        "print(model2.compile())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCk7QX0vL77t",
        "outputId": "29cf283c-300f-4c12-deaf-4db15e7f5fe0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): EmbedLayer_replace(\n",
            "    (embedding): Embedding(402348, 100)\n",
            "    (oov_embedding): Embedding(402348, 100)\n",
            "  )\n",
            "  (1): LSTMLayer(\n",
            "    (lstm): LSTM(100, 1000, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (2): Linear(in_features=2000, out_features=1000, bias=True)\n",
            "  (3): Linear(in_features=1000, out_features=46, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.train(x_train, y_train, x_validation, y_validation, batch_size=500, epochs=1)"
      ],
      "metadata": {
        "id": "Sz3veASQEX1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1a7a630-f1e1-438f-96ab-011888af4cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 1/94 ----- loss: 63.37822723388672 ----- accuracy: 0.044 \n",
            "batch 2/94 ----- loss: 53.45209503173828 ----- accuracy: 0.134 \n",
            "batch 3/94 ----- loss: 57.832603454589844 ----- accuracy: 0.154 \n",
            "batch 4/94 ----- loss: 57.55810546875 ----- accuracy: 0.046 \n",
            "batch 5/94 ----- loss: 71.75276184082031 ----- accuracy: 0.11 \n",
            "batch 6/94 ----- loss: 71.0855712890625 ----- accuracy: 0.006 \n",
            "batch 7/94 ----- loss: 88.05654907226562 ----- accuracy: 0.068 \n",
            "batch 8/94 ----- loss: 107.15592956542969 ----- accuracy: 0.042 \n",
            "batch 9/94 ----- loss: 108.02288818359375 ----- accuracy: 0.028 \n",
            "batch 10/94 ----- loss: 104.12541961669922 ----- accuracy: 0.036 \n",
            "batch 11/94 ----- loss: 119.5931625366211 ----- accuracy: 0.008 \n",
            "batch 12/94 ----- loss: 118.44950866699219 ----- accuracy: 0.004 \n",
            "batch 13/94 ----- loss: 95.90664672851562 ----- accuracy: 0.034 \n",
            "batch 14/94 ----- loss: 93.52590942382812 ----- accuracy: 0.024 \n",
            "batch 15/94 ----- loss: 81.55779266357422 ----- accuracy: 0.088 \n",
            "batch 16/94 ----- loss: 80.20886993408203 ----- accuracy: 0.078 \n",
            "batch 17/94 ----- loss: 75.9555892944336 ----- accuracy: 0.006 \n",
            "batch 18/94 ----- loss: 69.40219116210938 ----- accuracy: 0.0 \n",
            "batch 19/94 ----- loss: 64.69731903076172 ----- accuracy: 0.03 \n",
            "batch 20/94 ----- loss: 60.18943786621094 ----- accuracy: 0.116 \n",
            "batch 21/94 ----- loss: 70.26002502441406 ----- accuracy: 0.174 \n",
            "batch 22/94 ----- loss: 78.50364685058594 ----- accuracy: 0.096 \n",
            "batch 23/94 ----- loss: 65.27079010009766 ----- accuracy: 0.18 \n",
            "batch 24/94 ----- loss: 72.2839126586914 ----- accuracy: 0.152 \n",
            "batch 25/94 ----- loss: 59.208065032958984 ----- accuracy: 0.104 \n",
            "batch 26/94 ----- loss: 58.6694450378418 ----- accuracy: 0.116 \n",
            "batch 27/94 ----- loss: 50.84880447387695 ----- accuracy: 0.132 \n",
            "batch 28/94 ----- loss: 60.954505920410156 ----- accuracy: 0.164 \n",
            "batch 29/94 ----- loss: 56.228004455566406 ----- accuracy: 0.092 \n",
            "batch 30/94 ----- loss: 53.388668060302734 ----- accuracy: 0.14 \n",
            "batch 31/94 ----- loss: 40.44923400878906 ----- accuracy: 0.122 \n",
            "batch 32/94 ----- loss: 39.01723098754883 ----- accuracy: 0.14 \n",
            "batch 33/94 ----- loss: 41.426666259765625 ----- accuracy: 0.154 \n",
            "batch 34/94 ----- loss: 38.70811462402344 ----- accuracy: 0.114 \n",
            "batch 35/94 ----- loss: 34.62842559814453 ----- accuracy: 0.188 \n",
            "batch 36/94 ----- loss: 39.07673263549805 ----- accuracy: 0.136 \n",
            "batch 37/94 ----- loss: 32.36130905151367 ----- accuracy: 0.232 \n",
            "batch 38/94 ----- loss: 43.975318908691406 ----- accuracy: 0.068 \n",
            "batch 39/94 ----- loss: 34.62592315673828 ----- accuracy: 0.09 \n",
            "batch 40/94 ----- loss: 37.41838455200195 ----- accuracy: 0.038 \n",
            "batch 41/94 ----- loss: 32.3317756652832 ----- accuracy: 0.006 \n",
            "batch 42/94 ----- loss: 26.53094482421875 ----- accuracy: 0.142 \n",
            "batch 43/94 ----- loss: 26.9208984375 ----- accuracy: 0.286 \n",
            "batch 44/94 ----- loss: 30.672853469848633 ----- accuracy: 0.2 \n",
            "batch 45/94 ----- loss: 31.803430557250977 ----- accuracy: 0.134 \n",
            "batch 46/94 ----- loss: 31.00967788696289 ----- accuracy: 0.242 \n",
            "batch 47/94 ----- loss: 23.179443359375 ----- accuracy: 0.302 \n",
            "batch 48/94 ----- loss: 30.539249420166016 ----- accuracy: 0.224 \n",
            "batch 49/94 ----- loss: 38.09376907348633 ----- accuracy: 0.098 \n",
            "batch 50/94 ----- loss: 33.07126235961914 ----- accuracy: 0.254 \n",
            "batch 51/94 ----- loss: 21.05826759338379 ----- accuracy: 0.446 \n",
            "batch 52/94 ----- loss: 30.91007423400879 ----- accuracy: 0.172 \n",
            "batch 53/94 ----- loss: 26.416019439697266 ----- accuracy: 0.144 \n",
            "batch 54/94 ----- loss: 27.37123680114746 ----- accuracy: 0.182 \n",
            "batch 55/94 ----- loss: 25.990741729736328 ----- accuracy: 0.254 \n",
            "batch 56/94 ----- loss: 27.92790985107422 ----- accuracy: 0.246 \n",
            "batch 57/94 ----- loss: 29.796955108642578 ----- accuracy: 0.14 \n",
            "batch 58/94 ----- loss: 24.131635665893555 ----- accuracy: 0.326 \n",
            "batch 59/94 ----- loss: 22.455978393554688 ----- accuracy: 0.122 \n",
            "batch 60/94 ----- loss: 31.75436019897461 ----- accuracy: 0.098 \n",
            "batch 61/94 ----- loss: 31.36286735534668 ----- accuracy: 0.188 \n",
            "batch 62/94 ----- loss: 29.697311401367188 ----- accuracy: 0.21 \n",
            "batch 63/94 ----- loss: 30.142257690429688 ----- accuracy: 0.192 \n",
            "batch 64/94 ----- loss: 26.333532333374023 ----- accuracy: 0.208 \n",
            "batch 65/94 ----- loss: 26.81125259399414 ----- accuracy: 0.204 \n",
            "batch 66/94 ----- loss: 29.86898422241211 ----- accuracy: 0.26 \n",
            "batch 67/94 ----- loss: 26.68950080871582 ----- accuracy: 0.284 \n",
            "batch 68/94 ----- loss: 24.15005111694336 ----- accuracy: 0.162 \n",
            "batch 69/94 ----- loss: 28.03447723388672 ----- accuracy: 0.258 \n",
            "batch 70/94 ----- loss: 22.477766036987305 ----- accuracy: 0.374 \n",
            "batch 71/94 ----- loss: 23.75082015991211 ----- accuracy: 0.402 \n",
            "batch 72/94 ----- loss: 20.027976989746094 ----- accuracy: 0.274 \n",
            "batch 73/94 ----- loss: 27.710376739501953 ----- accuracy: 0.242 \n",
            "batch 74/94 ----- loss: 29.128864288330078 ----- accuracy: 0.272 \n",
            "batch 75/94 ----- loss: 21.164169311523438 ----- accuracy: 0.278 \n",
            "batch 76/94 ----- loss: 18.64663314819336 ----- accuracy: 0.226 \n",
            "batch 77/94 ----- loss: 23.022384643554688 ----- accuracy: 0.2 \n",
            "batch 78/94 ----- loss: 23.98013687133789 ----- accuracy: 0.098 \n",
            "batch 79/94 ----- loss: 19.6483097076416 ----- accuracy: 0.294 \n",
            "batch 80/94 ----- loss: 24.471437454223633 ----- accuracy: 0.11 \n",
            "batch 81/94 ----- loss: 17.572738647460938 ----- accuracy: 0.258 \n",
            "batch 82/94 ----- loss: 14.15847110748291 ----- accuracy: 0.244 \n",
            "batch 83/94 ----- loss: 17.88491439819336 ----- accuracy: 0.252 \n",
            "batch 84/94 ----- loss: 26.98000144958496 ----- accuracy: 0.058 \n",
            "batch 85/94 ----- loss: 20.409324645996094 ----- accuracy: 0.33 \n",
            "batch 86/94 ----- loss: 31.708215713500977 ----- accuracy: 0.17 \n",
            "batch 87/94 ----- loss: 20.560884475708008 ----- accuracy: 0.294 \n",
            "batch 88/94 ----- loss: 17.083898544311523 ----- accuracy: 0.324 \n",
            "batch 89/94 ----- loss: 27.29706573486328 ----- accuracy: 0.21 \n",
            "batch 90/94 ----- loss: 22.00832748413086 ----- accuracy: 0.226 \n",
            "batch 91/94 ----- loss: 28.51573944091797 ----- accuracy: 0.208 \n",
            "batch 92/94 ----- loss: 27.862123489379883 ----- accuracy: 0.314 \n",
            "batch 93/94 ----- loss: 28.56037139892578 ----- accuracy: 0.292 \n",
            "batch 94/94 ----- loss: 28.89754295349121 ----- accuracy: 0.272 \n",
            "batch 95/94 ----- loss: 28.086883544921875 ----- accuracy: 0.3258426966292135 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-168370473c72>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-8e3fa3fe8276>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_validation, y_validation, learning_rate, epochs, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# ----------------- VALIDATION  ----------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mval_accuracy_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mval_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYMHZEeMPWg1"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0AFgk7qPWg2"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRbAjydQPWg2"
      },
      "source": [
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rt8yXVMPWg2"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1SoEvCkPWg3"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_DGswu1PWg3"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7c7KDbPWg4"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az6O5TuxPWg4"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUJ9UKMZPWg5"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkUvb_LkPWg5"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K62xEDwFPWg6"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "017zL6z1PWg6"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYjOdgbMPWg6"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUsAIjyYPWg7"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62oRvXM2PWg7"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULplO2tTPWg8"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNEBeS9HPWg8"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snebFw_VPWg9"
      },
      "source": [
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9sTFDJrPWg9"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
